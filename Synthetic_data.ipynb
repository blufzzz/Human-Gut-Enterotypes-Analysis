{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "historical-length",
   "metadata": {
    "id": "historical-length"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a2e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 37556\r\n",
      "drwxr-xr-x 2 ibulygin users    4096 авг 12  2022 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxr-xr-x 5 ibulygin users    4096 апр  3 01:03 \u001b[01;34m..\u001b[0m/\r\n",
      "-rw-r--r-- 1 ibulygin users 6353146 авг 12  2022 clust2_dim108\r\n",
      "-rw-r--r-- 1 ibulygin users 2320137 авг 12  2022 clust2_dim39\r\n",
      "-rw-r--r-- 1 ibulygin users 4131985 авг 12  2022 clust2_dim70\r\n",
      "-rw-r--r-- 1 ibulygin users 6365095 авг 12  2022 clust3_dim108\r\n",
      "-rw-r--r-- 1 ibulygin users 2312774 авг 12  2022 clust3_dim39\r\n",
      "-rw-r--r-- 1 ibulygin users 4136186 авг 12  2022 clust3_dim70\r\n",
      "-rw-r--r-- 1 ibulygin users 6357540 авг 12  2022 clust4_dim108\r\n",
      "-rw-r--r-- 1 ibulygin users 2322444 авг 12  2022 clust4_dim39\r\n",
      "-rw-r--r-- 1 ibulygin users 4131976 авг 12  2022 clust4_dim70\r\n"
     ]
    }
   ],
   "source": [
    "ls -la data/synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc96d44",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "930e770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_synth = 'data/synthetic/'\n",
    "os.makedirs(root_synth, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df2c8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "ADD_NOISE = True\n",
    "N = 3000\n",
    "\n",
    "np.random.seed(42)\n",
    "for i,n_clust in tqdm(enumerate([2,3,4])):\n",
    "    for j,dim in enumerate([39,70,108]): # [53,96,180]\n",
    "        \n",
    "        label = f'C{n_clust}_d_{dim}'\n",
    "\n",
    "        # make data\n",
    "        centers = np.pad(np.eye(n_clust), pad_width=((0,0),(0,dim - n_clust)))*2\n",
    "        centers += np.random.randn(*centers.shape)*1\n",
    "        X,y = make_blobs(n_samples=int(N*0.9), n_features=dim, centers=centers, cluster_std=0.5)\n",
    "        if ADD_NOISE:\n",
    "            X_ = X-X.mean(0)\n",
    "            cov = (X_).T@X_/(X.shape[0]-1)\n",
    "            cov_ = np.zeros_like(cov)\n",
    "            cov_[np.diag_indices_from(cov)] = np.sqrt(cov[np.diag_indices_from(cov)])*2\n",
    "            X_noise = np.random.multivariate_normal(X.mean(0), cov_, size=int(N*0.1))\n",
    "\n",
    "            y_noise = np.zeros((int(N*0.1),))\n",
    "            y_noise += max(y) + 1 # add separate class for the noise\n",
    "            X = np.concatenate([X,X_noise])\n",
    "            y = np.concatenate((y, y_noise))\n",
    "\n",
    "        df = pd.DataFrame(X)\n",
    "        df['target'] = y\n",
    "        name = f'clust{n_clust}_dim{dim}'\n",
    "        dataset_path = os.path.join(root_synth, name)\n",
    "        df.to_csv(dataset_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Synthetic_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
