{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "historical-length",
   "metadata": {
    "id": "historical-length"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc96d44",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "930e770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_synth = 'data/synthetic/'\n",
    "os.makedirs(root_synth, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df2c8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "ADD_NOISE = True\n",
    "N = 3000\n",
    "\n",
    "np.random.seed(42)\n",
    "for i,n_clust in tqdm(enumerate([2,3,4])):\n",
    "    for j,dim in enumerate([39,70,108]): # [53,96,180]\n",
    "        \n",
    "        label = f'C{n_clust}_d_{dim}'\n",
    "\n",
    "        # make data\n",
    "        centers = np.pad(np.eye(n_clust), pad_width=((0,0),(0,dim - n_clust)))*2\n",
    "        centers += np.random.randn(*centers.shape)*1\n",
    "        X,y = make_blobs(n_samples=int(N*0.9), n_features=dim, centers=centers, cluster_std=0.5)\n",
    "        if ADD_NOISE:\n",
    "            X_ = X-X.mean(0)\n",
    "            cov = (X_).T@X_/(X.shape[0]-1)\n",
    "            cov_ = np.zeros_like(cov)\n",
    "            cov_[np.diag_indices_from(cov)] = np.sqrt(cov[np.diag_indices_from(cov)])*2\n",
    "            X_noise = np.random.multivariate_normal(X.mean(0), cov_, size=int(N*0.1))\n",
    "\n",
    "            y_noise = np.zeros((int(N*0.1),))\n",
    "            y_noise += max(y) + 1 # add separate class for the noise\n",
    "            X = np.concatenate([X,X_noise])\n",
    "            y = np.concatenate((y, y_noise))\n",
    "\n",
    "        df = pd.DataFrame(X)\n",
    "        df['target'] = y\n",
    "        name = f'clust{n_clust}_dim{dim}'\n",
    "        dataset_path = os.path.join(root_synth, name)\n",
    "        df.to_csv(dataset_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Synthetic_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
